{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- require 'VGG';\n",
    "require 'nn';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- require 'VGG';\n",
    "-- VGG_net = load_VGG();\n",
    "-- print('VGGnet5\\n' .. VGG_net:__tostring());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- local layer_nums = {9,16}\n",
    "-- local num_images = 20;\n",
    "-- hc_dataset = create_hypercolumn_dataset(num_images, layer_nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Loading the data from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hc_file_name = '../../Data/tiny-imagenet-200/test/hc/test.t7'\n",
    "hc_dataset = torch.load(hc_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  20\n",
       " 384\n",
       " 112\n",
       " 112\n",
       "[torch.LongStorage of size 4]\n",
       "\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypercolumns = hc_dataset[\"hypercolumns\"]\n",
    "images = hc_dataset[\"images\"]\n",
    "print(hypercolumns:size())\n",
    "num_hypercolumns = hypercolumns:size()[2]\n",
    "batch_size = hypercolumns:size()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Converting the data labels from rgb to uv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 20\n",
       "  2\n",
       " 28\n",
       " 28\n",
       "[torch.LongStorage of size 4]\n",
       "\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local yuv_temp = image.rgb2yuv(images[1]);\n",
    "yuv_temp = image.scale(yuv_temp,28,28,'bilinear')\n",
    "local uv_temp = yuv_temp[{{2,3}}]\n",
    "uv_temp = uv_temp:reshape(1,uv_temp:size()[1], uv_temp:size()[2], uv_temp:size()[3] );\n",
    "uv_images = uv_temp\n",
    "\n",
    "for count=2,batch_size do\n",
    "    yuv_temp = image.rgb2yuv(images[count]);\n",
    "    yuv_temp = image.scale(yuv_temp,28,28,'bilinear')\n",
    "    uv_temp = yuv_temp[{{2,3}}]\n",
    "    uv_temp = uv_temp:reshape(1,uv_temp:size()[1], uv_temp:size()[2], uv_temp:size()[3]);\n",
    "    uv_images = torch.cat(uv_images,uv_temp,1)\n",
    "end\n",
    "    print(uv_images:size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing the trainset datastructure.\n",
    "The format should be as follows\n",
    "1) Trainset.data = contains **X minibatches**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainset={};\n",
    "trainset.data = torch.Tensor(1, hypercolumns:size()[1],hypercolumns:size()[2],hypercolumns:size()[3],hypercolumns:size()[4])\n",
    "trainset.label = torch.Tensor(1,uv_images:size()[1],uv_images:size()[2],uv_images:size()[3],uv_images:size()[4])\n",
    "function trainset:size() return 20 end -- 100 examples\n",
    "for i=1,trainset:size() do \n",
    "  trainset.data[1][i] = hypercolumns[i]\n",
    "  trainset.label[1][i] = uv_images[i] \n",
    "end\n",
    "\n",
    "setmetatable(trainset, \n",
    "    {__index = function(t, i) \n",
    "                    return {t.data[i], t.label[i]} \n",
    "                end}\n",
    ");\n",
    "trainset.data = trainset.data:double() -- convert the data from a ByteTensor to a DoubleTensor.\n",
    "\n",
    "function trainset:size() \n",
    "    return self.data:size(1) \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require \"nn\"\n",
    "require \"torch\"\n",
    "\n",
    "function BasicConvNet1()\n",
    "    -- Number of filters in different layers \n",
    "    net = nn.Sequential()\n",
    "    HyperColumnHeight = num_hypercolumns\n",
    "    Layer1FilterNum = 32\n",
    "    Layer2FilterNum = 64\n",
    "    Layer3FilterNum = 2\n",
    "\n",
    "\n",
    "    -- [[ Layer 1 ]]\n",
    "    -- HyperColumnHeight input image channel, Layer1FilterNum output channels, 3x3 convolution kernel, 1 stride W, 1 stride H, 1 pad W, 1 pad R\n",
    "    net:add(nn.SpatialConvolution(HyperColumnHeight, Layer1FilterNum, 3, 3, 1, 1, 1, 1)) \n",
    "    -- Batch Normalization\n",
    "    net:add(nn.SpatialBatchNormalization(Layer1FilterNum))                       \n",
    "    -- ReLU non-linearity\n",
    "    net:add(nn.ReLU())\n",
    "    -- 2x2 max-pooling\n",
    "    net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "\n",
    "\n",
    "    -- [[ Layer 2 ]]\n",
    "    -- Layer1FilterNum input image channel, Layer2FilterNum output channels, 3x3 convolution kernel, 1 stride W, 1 stride H, 1 pad W, 1 pad R\n",
    "    net:add(nn.SpatialConvolution(Layer1FilterNum, Layer2FilterNum, 3, 3, 1, 1, 1, 1)) \n",
    "    -- Batch Normalization\n",
    "    net:add(nn.SpatialBatchNormalization(Layer2FilterNum))                       \n",
    "    -- ReLU non-linearity\n",
    "    net:add(nn.ReLU())\n",
    "    -- 2x2 max-pooling\n",
    "    net:add(nn.SpatialMaxPooling(2,2,2,2))\n",
    "\n",
    "    --[[ Layer 3 ]]\n",
    "    -- Layer2FilterNum input image channel, Layer3FilterNum output channels, 3x3 convolution kernel, 1 stride W, 1 stride H, 1 pad W, 1 pad R\n",
    "    net:add(nn.SpatialConvolution(Layer2FilterNum, Layer3FilterNum, 3, 3, 1, 1, 1, 1)) \n",
    "    -- Adding transfer function sigmod \n",
    "    net:add(nn.Sigmoid())  \n",
    "\n",
    "    net:zeroGradParameters()\n",
    "    return net\n",
    "\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet Loaded\t\n",
       "MSEcriterion defined\t\n",
       "Trainer defined\t\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Loading the net\n",
    "require('Net1')\n",
    "net = BasicConvNet1()\n",
    "print('ConvNet Loaded')\n",
    "\n",
    "-- Defining a loss function\n",
    "Weight = torch.ones(2,28,28)-- All ones matrix -- Bad coding\n",
    "criterion = nn.WeightedMSECriterion(Weight)\n",
    "print('MSEcriterion defined')\n",
    "\n",
    "trainer = nn.StochasticGradient(net, criterion)\n",
    "-- learning rate init\n",
    "trainer.learningRate = 0.1 --\n",
    "-- Number of Epocs\n",
    "trainer.maxIteration = 10\n",
    "trainer.verbose = true\n",
    "trainer.shuffleIndices = false\n",
    "trainer.learningRateDecay = .9\n",
    "print('Trainer defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No code error during sanity check (Logical error might still exist)\t\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Passing a random input\n",
    "input = torch.rand(2,384,112,112) -- pass a random tensor as input to the network\n",
    "-- Obtain the output\n",
    "output = net:forward(input)\n",
    "\n",
    "-- Checking the backward pass using a fake expected output\n",
    "ExpectedFakeOutput = torch.rand( output:size() )\n",
    "criterion:forward(output, ExpectedFakeOutput) -- let's say the groundtruth was class number: 3\n",
    "gradients = criterion:backward(output, ExpectedFakeOutput)\n",
    "print(\"No code error during sanity check (Logical error might still exist)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--print(\"Initial error\", criterion:forward(net:forward(input), target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The training starts\t\n",
       "# StochasticGradient: training\t\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.25480228315934\t\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.091289380870282\t\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.056995789539028\t\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.039707088927151\t\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# current error = 0.029691080516024\t\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "# StochasticGradient: you have reached the maximum number of iterations\t\n",
       "# training error = 0.029691080516024\t\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('The training starts')\n",
    "-- Woah! Traingin the data\n",
    "trainer:train(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = net:forward(hypercolumns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 2\n",
    "itorch.image(a[i] )\n",
    "itorch.image(uv_images[i]  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
