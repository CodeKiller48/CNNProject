{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'loadcaffe'\n",
    "require 'image'\n",
    "prototxt = '../../Data/VGG_caffe/VGG_ILSVRC_16_layers_deploy.prototxt'\n",
    "binary = '../../Data/VGG_caffe/VGG_ILSVRC_16_layers.caffemodel'\n",
    "\n",
    "-- this will load the network and print it's structure\n",
    "net = loadcaffe.load(prototxt, binary);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "-- Loads the mapping from net outputs to human readable labels\n",
    "function load_synset()\n",
    "  local list = {}\n",
    "  for line in io.lines'synset_words.txt' do\n",
    "    table.insert(list, string.sub(line,11))\n",
    "  end\n",
    "  return list\n",
    "end\n",
    "\n",
    "function preprocess(img) \n",
    "-- 16 layer VGG expects a 3x224x224 sized image\n",
    "  img = image.scale(img, 224, 224)\n",
    "-- Directly obtained from the website\n",
    "  local mean_pixel = torch.DoubleTensor({103.939, 116.779, 123.68})\n",
    "-- Permuting from RBG to BGR\n",
    "  local perm = torch.LongTensor{3, 2, 1}\n",
    "-- Scaling the elements from 0:1 to 0:256\n",
    "  img = img:index(1, perm):mul(256.0)\n",
    "  mean_pixel = mean_pixel:view(3, 1, 1):expandAs(img)\n",
    "-- Subtracting the mean\n",
    "  img:add(-1, mean_pixel)\n",
    "  return img\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_name = '../../Data/tiny-imagenet-200/test/images/test_4.JPEG'\n",
    "-- loading thr image\n",
    "im1 = image.load(image_name)\n",
    "-- Rotating the image by 180 degree\n",
    "im = image.rotate(im1,3.14159)\n",
    "-- Display \n",
    "itorch.image(im) -- rescale just to show the image-- displaying the image\n",
    "\n",
    "-- Convolving with a smoothing filter \n",
    "conv_kernel = torch.ones(2,2)\n",
    "imc = image.convolve(im1,conv_kernel,'full')\n",
    "itorch.image(image.scale(imc, 224, 224)) -- rescale just to show the image-- displaying the image\n",
    "im = preprocess(im)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Preprocessing the image so and then feeding it to the VGG net.\n",
    "prob,classes = net:forward(im):view(-1):sort(true) -- forward pass > resize to a single column > sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Printing the class predicted by VGG net.\n",
    "synset_words = load_synset()\n",
    "\n",
    "for i=1,5 do\n",
    "  print('predicted class '..tostring(i)..': ', synset_words[classes[i]])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Accessing intermediate layers\n",
    "layer_1 = net.modules[2].output\n",
    "print(layer_1:size())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rescaled_layer_1 = image.scale(layer_1,224,224,'simple');\n",
    "itorch.image(rescaled_layer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Creating the hypercolumns\n",
    "layer_1 = net.modules[5].output;\n",
    "hyper_columns = image.scale(layer_1,224,224,'simple');\n",
    "layer_nums = {9,16,23,30}\n",
    "for i=1,3 do\n",
    "    layer = net.modules[layer_nums[i]].output\n",
    "    hyper_columns = torch.cat(hyper_columns,image.scale(layer,224,224,'simple'),1)\n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "--itorch.image(image.scale(hyper_columns,224,224))\n",
    "itorch.image(hyper_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require(\"Utils\")\n",
    "image_name = '../../Data/tiny-imagenet-200/test/images/test_4.JPEG'\n",
    "-- loading thr image\n",
    "im = image.load(image_name)\n",
    "itorch.image(im)\n",
    "-- Calling the rgb2gray function\n",
    "grayim = rgb2gray(im)\n",
    "itorch.image(grayim)\n",
    "-- Calling the gray2rbg function\n",
    "\n",
    "grayim3 = gray2rgb(grayim)\n",
    "itorch.image(grayim3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hc = {hyper_columns,hyper_columns}\n",
    "hc_file_name = '../../Data/tiny-imagenet-200/test/hc/test_4.t7'\n",
    "torch.save(hc_file_name, hc, \"binary\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hc_loaded = torch.load(hc_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "itorch.image(hyper_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
