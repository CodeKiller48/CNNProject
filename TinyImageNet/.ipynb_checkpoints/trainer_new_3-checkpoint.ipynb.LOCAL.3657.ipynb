{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'Utils'\n",
    "require 'Net1'\n",
    "require 'VGG'\n",
    "require 'optim'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Successfully loaded ../../Data/VGG_caffe/VGG_ILSVRC_16_layers.caffemodel\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv1_1: 64 3 3 3\n",
       "conv1_2: 64 64 3 3\n",
       "conv2_1: 128 64 3 3\n",
       "conv2_2: 128 128 3 3\n",
       "conv3_1: 256 128 3 3\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv3_2: 256 256 3 3\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv3_3: 256 256 3 3\n",
       "conv4_1: 512 256 3 3\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv4_2: 512 512 3 3\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv4_3: 512 512 3 3\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv5_1: 512 512 3 3\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv5_2: 512 512 3 3\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "conv5_3: 512 512 3 3\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "fc6: 1 1 25088 4096\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "fc7: 1 1 4096 4096\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "fc8: 1 1 4096 1000\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       " i = 1 / 2, loss = 0.015843\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       " i = 2 / 2, loss = 0.102972\t\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local dtype = 'torch.DoubleTensor'\n",
    "\n",
    "VGG_net = load_VGG();\n",
    "model = BasicConvNet2()\n",
    "local params, grad_params = model:getParameters()\n",
    "local crit = nn.MSECriterion():type(dtype)\n",
    "\n",
    "-- Set up some variables we will use below\n",
    "local train_loss_history = {}\n",
    "\n",
    "-- Contains all the meta parameters\n",
    "local opt = {num_iterations=2, print_every=1, learning_rate=0.01, batch_size = 2, layers = {3,9}}\n",
    "\n",
    "--Triming the network will the last required layer \n",
    "trim_net(VGG_net, opt.layers[#opt.layers])\n",
    "\n",
    "-- Get a minibatch and run the model forward, maybe timing it\n",
    "-- im_batch, x = create_hypercolumn_dataset_random_bw(opt.batch_size, VGG_net, opt.layers);\n",
    "-- uv_images, y_images = create_yuv_images(im_batch,28,28)\n",
    "-- uv_images = uv_images + 0.5\n",
    "\n",
    "-- -- Datatype standardization \n",
    "-- x, uv_images = x:type(dtype), uv_images:type(dtype)\n",
    "\n",
    "-- Loss function that we pass to an optim method\n",
    "local function f(w)\n",
    "--  assert(w == params)\n",
    "  grad_params:zero()\n",
    "\n",
    "--   -- Get a minibatch and run the model forward, maybe timing it\n",
    "  local im_batch, x = create_hypercolumn_dataset_random_bw(opt.batch_size, VGG_net, opt.layers);\n",
    "  local uv_images, y_images = create_yuv_images(im_batch,28,28)\n",
    "  uv_images = uv_images + 0.5\n",
    "  \n",
    "  -- Datatype standardization \n",
    "  x, uv_images = x:type(dtype), uv_images:type(dtype)\n",
    "\n",
    "  local scores = model:forward(x)\n",
    "  local loss   = crit:forward(scores, uv_images)\n",
    "\n",
    "  -- Run the Criterion and model backward to compute gradients, maybe timing it\n",
    "  local grad_scores = crit:backward(scores, uv_images)\n",
    "  model:backward(x, grad_scores)\n",
    "--   print(\"grad params\", grad_params)\n",
    "  return loss, grad_params\n",
    "end\n",
    "\n",
    "\n",
    "-- Train the model!\n",
    "local optim_config = {learningRate = opt.learning_rate}\n",
    "local num_iterations = opt.num_iterations\n",
    "for i = 1, num_iterations do\n",
    "\n",
    "  -- Take a gradient step and maybe print\n",
    "  -- Note that adam returns a singleton array of losses\n",
    "  local _, loss = optim.adam(f, params, optim_config)\n",
    "  table.insert(train_loss_history, loss[1])\n",
    "  if opt.print_every > 0 and i % opt.print_every == 0 then\n",
    "    local msg = ' i = %d / %d, loss = %f'\n",
    "    local args = {msg,  i, num_iterations, loss[1]}\n",
    "    print(string.format(unpack(args)))\n",
    "  end\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function y2rgb(y_temp)\n",
    "    im_y = torch.cat(y_temp,y_temp,1);\n",
    "    im_y = torch.cat(im_y,y_temp,1);\n",
    "    return im_y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "uv_op = model.output - 0.5\n",
    "for i = 2,6 do\n",
    "    size = 96\n",
    "    itorch.image({image.scale(y2rgb(image.rgb2y(im_batch[i])),size,size),\n",
    "                  image.scale(image.yuv2rgb(torch.cat(y_images[i],uv_op[i],1)),size,size),\n",
    "                  image.scale(image.yuv2rgb(torch.cat(y_images[i],uv_images[i]-0.5,1)),size,size)})\n",
    "    -- itorch.image(image.scale(im_batch[i],size,size))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "local layer_nums = {3,9}\n",
    "local num_images = 16;\n",
    "val_im_batch,val_hc_batch = create_hypercolumn_dataset_random_bw(num_images, VGG_net,layer_nums)\n",
    "-- val_im_batch,val_hc_batch = create_hypercolumn_dataset_random(num_images, layer_nums);\n",
    "hc_size = val_hc_batch:size()\n",
    "num_hypercolumns = hc_size[2]\n",
    "uv_images,y_images = create_yuv_images(val_im_batch,28,28)\n",
    "model:forward(val_hc_batch);\n",
    "val_uv = model.output -0.5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "im_batch = val_im_batch\n",
    "uv_op = val_uv\n",
    "print(\"Input, Output, Original\")\n",
    "for i = 1,16 do\n",
    "    size = 96\n",
    "    itorch.image({image.scale(y2rgb(image.rgb2y(im_batch[i])),size,size),\n",
    "                  image.scale(image.yuv2rgb(torch.cat(y_images[i],uv_op[i],1)),size,size),\n",
    "                  image.scale(image.yuv2rgb(torch.cat(y_images[i],uv_images[i],1)),size,size)})\n",
    "    -- itorch.image(image.scale(im_batch[i],size,size))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "depth = 193\n",
    "net = BasicConvNet2();\n",
    "criterion = nn.MSECriterion()\n",
    "print('MSEcriterion defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "layer_nums = {3,9}\n",
    "num_images = 8;\n",
    "decay = 0.99;\n",
    "local train_loss_history = {}\n",
    "for i = 1,1 do\n",
    "    --im_batch,hc_batch = create_hypercolumn_dataset_random_bw(num_images, layer_nums, VGG_net);\n",
    "    hc_size = hc_batch:size()\n",
    "    num_hypercolumns = hc_size[2]\n",
    "    uv_images,y_images = create_yuv_images(im_batch,28,28)\n",
    "    lr = .2;\n",
    "    v  = 0\n",
    "    mu = .99\n",
    "    for j = 1,100 do\n",
    "        loss = criterion:forward(net:forward(hc_batch), uv_images+0.5)\n",
    "        print(\"batch: \".. i .. \") iter:\" .. j .. \" \" .. loss)\n",
    "        loss = net.output\n",
    "        net:backward(hc_batch, criterion:backward(loss, uv_images+0.5))\n",
    "        net:updateParameters(lr)\n",
    "        table.insert(train_loss_history, loss)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "uv_op = net.output-0.5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "itorch.image(torch.cat(y_images,uv_op,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = 4\n",
    "size = 28\n",
    "itorch.image(image.scale(y_images[i],size,size))\n",
    "itorch.image(image.scale(image.yuv2rgb(torch.cat(y_images[i],uv_op[i],1)),size,size))\n",
    "itorch.image(image.scale(image.yuv2rgb(torch.cat(y_images[i],uv_images[i],1)),size,size))\n",
    "itorch.image(image.scale(im_batch[i],size,size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "local layer_nums = {3,9}\n",
    "local num_images = 8;\n",
    "val_im_batch,val_hc_batch = create_hypercolumn_dataset_random_bw(num_images, layer_nums)\n",
    "-- val_im_batch,val_hc_batch = create_hypercolumn_dataset_random(num_images, layer_nums);\n",
    "hc_size = val_hc_batch:size()\n",
    "num_hypercolumns = hc_size[2]\n",
    "uv_images,y_images = create_yuv_images(val_im_batch,28,28)\n",
    "net:forward(val_hc_batch);\n",
    "val_uv = net.output -0.5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "local num_images = 8;\n",
    "for iter=1,num_images do\n",
    "    itorch.image(image.scale(image.yuv2rgb(torch.cat(y_images[iter],val_uv[iter],1)),224,224))\n",
    "    itorch.image(image.scale(im_batch[iter],224,224))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "local layer_nums = {3,9}\n",
    "local num_images = 8;\n",
    "-- val_im_batch,val_hc_batch = create_hypercolumn_dataset_random_bw(num_images, layer_nums)\n",
    "val_im_batch,val_hc_batch = create_hypercolumn_dataset_random(num_images, layer_nums);\n",
    "hc_size = val_hc_batch:size()\n",
    "num_hypercolumns = hc_size[2]\n",
    "uv_images,y_images = create_yuv_images(val_im_batch,28,28)\n",
    "net:forward(val_hc_batch);\n",
    "val_uv = net.output -0.5;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "local num_images = 8;\n",
    "for iter=1,num_images do\n",
    "    itorch.image(image.scale(image.yuv2rgb(torch.cat(y_images[iter],val_uv[iter],1)),224,224))\n",
    "    itorch.image(image.scale(im_batch[iter],224,224))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
